{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StackGAN Models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "hi\n"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from initValues import config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "# Upsale the spatial size by a factor of 2\n",
        "def upBlock(inPlanes, outPlanes):\n",
        "    block = nn.Sequential(\n",
        "        nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "        ConvBlock(inPlanes, outPlanes, kernel_size = 3, stride = 1)\n",
        "        # conv3x3(in_planes, out_planes),\n",
        "        # nn.BatchNorm2d(out_planes),\n",
        "        # nn.ReLU(True))\n",
        "    )\n",
        "    return block\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, channelNum):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            ConvBlock(channelNum, channelNum, kernel_size=3, stride=1),\n",
        "            # conv3x3(channel_num, channel_num),\n",
        "            # nn.BatchNorm2d(channel_num),\n",
        "            # nn.ReLU(True),\n",
        "            conv3x3(channelNum, channelNum),\n",
        "            nn.BatchNorm2d(channelNum))\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.block(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class CA_NET(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CA_NET,self).__init__()\n",
        "    self.t_dim = config.TEXT.DIMENSION\n",
        "    self.c_dim = config.GAN.CONDITION_DIM\n",
        "    self.fc = nn.Linear(self.t_dim, self.c_dim * 2, bias=True)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def encode(self, text_embedding):\n",
        "    x = self.relu(self.fc(text_embedding))\n",
        "    mu = x[:, :self.c_dim]\n",
        "    logvar = x[:, self.c_dim:]\n",
        "    return mu, logvar\n",
        "\n",
        "  def reparametrize(self, mu, logvar):\n",
        "    std = logvar.mul(0.5).exp_()\n",
        "    if config.CUDA:\n",
        "      eps = torch.cuda.FloatTensor(std.size(), requires_grad = True).normal_()\n",
        "    else:\n",
        "      eps = torch.FloatTensor(std.size(), requires_grad = True).normal_()\n",
        "    return eps.mul(std).add_(mu)\n",
        "\n",
        "  def forward(self, text_embedding):\n",
        "     mu, logvar = self.encode(text_embedding)\n",
        "     c_code = self.reparametrize(mu, logvar)\n",
        "     return c_code, mu, logvar\n",
        "\n",
        "\n",
        "class Stage1_Gen(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Stage1_GAN, self).__init__()\n",
        "    self.gfDim = config.GAN.GF_DIM * 8\n",
        "    self.efDim = config.GAN.CONDITION_DIM\n",
        "    self.zDim = config.Z_DIM\n",
        "    self.defineModel()\n",
        "\n",
        "  def defineModel(self):\n",
        "    inp = self.zDim + self.efDim\n",
        "    ngf - self.gfDim\n",
        "    self.caNet = CA_NET()\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(inp, ngf * 4 * 4, bias = False),\n",
        "        nn.BatchNorm1d(ngf * 4 * 4),\n",
        "        nn.ReLU(True)\n",
        "    )\n",
        "    self.upSam = nn.Sequential(\n",
        "        upBlock(ngf, ngf//2),\n",
        "        upBlock(ngf // 2, ngf // 4),\n",
        "        upBlock(ngf // 4, ngf // 8),\n",
        "        upBlock(ngf // 8, ngf // 16)\n",
        "    )\n",
        "    # self.upSam1 = upBlock(ngf, ngf//2)\n",
        "    # self.upSam2 = upBlock(ngf // 2, ngf // 4)\n",
        "    # self.upSam3 = upBlock(ngf // 4, ngf // 8)\n",
        "    # self.upSam4 = upBlock(ngf // 8, ngf // 16)\n",
        "    \n",
        "    self.img = nn.Sequential(\n",
        "        conv3x3(ngf // 16, 3),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "  \n",
        "  def forward(self, textEmbedding, noise):\n",
        "    cCode , mu, logvar = self.caNet(textEmbedding)\n",
        "    zCCode = torch.cat((noise, cCode), 1)\n",
        "    hCode = self.net(zCCode)\n",
        "\n",
        "    hCode = hCode.view(-1, self.gfDim, 4, 4)\n",
        "    hCode = self.upSam(hCode)\n",
        "\n",
        "    fakeImg = self.img(hCode)\n",
        "    return None, fakeImg, mu, logvar\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, inpC, outC, kernel_size = 4, stride = 2, padding = 1, bias = False, BN = True, leaky = False):\n",
        "    super(ConvBlock, self).__init__()\n",
        "    self.BN = BN\n",
        "    self.leaky = leaky\n",
        "    self.conv = nn.Conv2d(inpC, outC, kernel_size, stride, padding, bias)\n",
        "    self.batchNorm = nn.BatchNorm2d(outC)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.leakyRelu = nn.LeakyReLU(0.2, inplace = True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv(x)\n",
        "    if BN:\n",
        "      out = self.batchNorm(out)\n",
        "    out = self.leakyRelu(out) if self.leaky else self.relu(out)\n",
        "    return out\n",
        "\n",
        "class Stage1_Dis(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Stage1_Dis, self).__init__()\n",
        "    self.dfDim = config.GAN.DF_DIM\n",
        "    self.efDim = config.GAN.CONDITION_DIM\n",
        "    self.defineModel()\n",
        "\n",
        "  def defineModel(self):\n",
        "    ndf, nef = self.dfDim, self.efDim\n",
        "\n",
        "    self.encodeImg = nn.Sequential(\n",
        "        ConvBlock(3, ndf, BN=False, leaky = True),\n",
        "        #(ndf) x 32 x 32\n",
        "        ConvBlock(ndf, ndf*2, leaky = True),\n",
        "        #(ndf*2) x 16 x 16\n",
        "        ConvBlock(ndf*2, ndf * 4, leaky = True),\n",
        "        #(ndf*4) x 8 x 8\n",
        "        ConvBlock(ndf * 4, ndf * 8, leaky = True)\n",
        "        #(ndf*8) x 4 x 4\n",
        "    )\n",
        "\n",
        "    self.getCondLogits = D_GetLogits(ndf, nef)\n",
        "\n",
        "  def forward(self, image):\n",
        "    imgEmbedding = self.encodeImg(image)\n",
        "    return imgEmbedding\n",
        "\n",
        "class Stage2_Gen(nn.Module):\n",
        "  def __init__(self, Stage1_Gen):\n",
        "    super(Stage2_Gen, self).__init__()\n",
        "    self.gfDim = config.GAN.GF_DIM\n",
        "    self.efDim = config.GAN.CONDITION_DIM\n",
        "    self.zDim = config.Z_DIM\n",
        "    self.stage1Gen = Stage1_Gen\n",
        "\n",
        "    for param in self.stage1Gen.parameters():\n",
        "      param.requires_grad = False\n",
        "    self.defineModel()\n",
        "\n",
        "  def _make_layer(self, block, channelNum):\n",
        "    layers = []\n",
        "    for i in range(config.GAN.R_NUM):\n",
        "      layers.append(block(channelNum))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def defineModel(self):\n",
        "    ngf = self.gfDim\n",
        "\n",
        "    self.caNet = CA+NET()\n",
        "\n",
        "    self.encoder = nn.Sequential(\n",
        "        ConvBlock(3, ngf, kernel_size=3, stride = 1, BN = False),\n",
        "        ConvBlock(ngf, ngf * 2),\n",
        "        ConvBlock(ngf * 2, ngf * 4)\n",
        "    )\n",
        "\n",
        "    self.hrJoint = nn.Sequential(\n",
        "        ConvBlock(self.efDim + ngf * 4, ngf * 4, kernel_size = 3, stride = 1)\n",
        "    )\n",
        "\n",
        "    self.residual = self._make_layer(ResBlock, ngf * 4)\n",
        "\n",
        "    self.upSam = nn.Sequential(\n",
        "        upBlock(ngf * 4, ngf * 2),\n",
        "        upBlock(ngf * 2, ngf),\n",
        "        upBlock(ngf, ngf // 2),\n",
        "        upBlock(ngf // 2, ngf // 4)\n",
        "    )\n",
        "\n",
        "    self.img = nn.Sequential(\n",
        "        nn.Conv2d(ngf // 4, 3, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, textEmbedding, noise):\n",
        "    _, stage1_Img, _, _ = self.Stage1_Gen(textEmbedding, noise)\n",
        "    stage1_Img = stage1_Img.detach()\n",
        "    encodedImg = self.encoder(stage1_Img)\n",
        "\n",
        "    cCode , mu, logvar = self.caNet(textEmbedding)\n",
        "    cCode = cCode.view(-1, self.efDim, 1, 1)\n",
        "    cCode = cCode.repeat(1, 1, 16, 16)\n",
        "    icCode = torch.cat([encodedImg, cCode], 1)\n",
        "    hCode = self.hrJoint(icCode)\n",
        "    hCode = self.residual(hCode)\n",
        "\n",
        "    hCode = self.upSam(hCode)\n",
        "\n",
        "    fakeImg = self.img(hCode)\n",
        "    return stage1_Img, fakeImg, mu, logvar\n",
        "\n",
        "class Stage2_Dis(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Stage2_Dis, self).__init__()\n",
        "    self.dfDim = config.GAN.DF_DIM\n",
        "    self.efDim = config.GAN.CONDITION_DIM\n",
        "    self.defineModel()\n",
        "\n",
        "  def defineModel(self):\n",
        "    ndf, nef = self.dfDim, self.efDim\n",
        "    self.encodeImg = nn.Sequential(\n",
        "        ConvBlock(3, ndf, BN = False, leaky = True),\n",
        "        #128 * 128 * (ndf)\n",
        "        ConvBlock(ndf, ndf * 2, leaky = True),\n",
        "        #64 x 64 x (ndf*2)\n",
        "        ConvBlock(ndf * 2, ndf * 4, leaky = True),\n",
        "        #32 x 32 x (ndf*4)\n",
        "        ConvBlock(ndf * 4, ndf * 8, leaky = True),\n",
        "        #16 x 16 x (ndf*8)\n",
        "        ConvBlock(ndf * 8, ndf * 16, leaky = True),\n",
        "        #8 x 8 x (ndf*16)\n",
        "        ConvBlock(ndf * 16, ndf * 32, leaky = True),\n",
        "        #4 x 4 x (ndf*32)\n",
        "\n",
        "        ConvBlock(ndf * 32, ndf * 16, kernel_size = 3, stride=1, leaky = True),\n",
        "        #4 x 4 x ndf * 16\n",
        "        ConvBlock(ndf * 16, ndf * 8, kernel_size = 3, stride=1, leaky = True)\n",
        "        #4 x 4 x ndf x 8\n",
        "    )\n",
        "\n",
        "    self.getCondLogits = D_GetLogits(ndf, nef, bcondition = True)\n",
        "    self.getUnCondLogits = D_GetLogits(ndf, nef, bcondition = False)\n",
        "\n",
        "  def forward(self, image):\n",
        "    imgEmbedding = seld.encodeImg(image)\n",
        "    return imgEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Ruz2nCPlCawg"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}